{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yG13MALn1uxg"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!lscpu"
      ],
      "metadata": {
        "id": "YgwdSbMXIR8a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cat /proc/cpuinfo"
      ],
      "metadata": {
        "id": "okNYFIHOCuya"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# anomaly detection model\n",
        "# https://github.com/mlcommons/tiny_results_v0.5/blob/main/closed/reference/code/training/anomaly_detection/keras_model.py\n",
        "def get_model(inputDim):\n",
        "    \"\"\"\n",
        "    define the keras model\n",
        "    the model based on the simple dense auto encoder \n",
        "    (128*128*128*128*8*128*128*128*128)\n",
        "    \"\"\"\n",
        "    inputLayer = tf.keras.layers.Input(shape=(inputDim,))\n",
        "\n",
        "    h = tf.keras.layers.Dense(128)(inputLayer)\n",
        "    h = tf.keras.layers.BatchNormalization()(h)\n",
        "    h = tf.keras.layers.Activation('relu')(h)\n",
        "\n",
        "    h = tf.keras.layers.Dense(128)(h)\n",
        "    h = tf.keras.layers.BatchNormalization()(h)\n",
        "    h = tf.keras.layers.Activation('relu')(h)\n",
        "\n",
        "    h = tf.keras.layers.Dense(128)(h)\n",
        "    h = tf.keras.layers.BatchNormalization()(h)\n",
        "    h = tf.keras.layers.Activation('relu')(h)\n",
        "\n",
        "    h = tf.keras.layers.Dense(128)(h)\n",
        "    h = tf.keras.layers.BatchNormalization()(h)\n",
        "    h = tf.keras.layers.Activation('relu')(h)\n",
        "\n",
        "    h = tf.keras.layers.Dense(8)(h)\n",
        "    h = tf.keras.layers.BatchNormalization()(h)\n",
        "    h = tf.keras.layers.Activation('relu')(h)\n",
        "\n",
        "    h = tf.keras.layers.Dense(128)(h)\n",
        "    h = tf.keras.layers.BatchNormalization()(h)\n",
        "    h = tf.keras.layers.Activation('relu')(h)\n",
        "\n",
        "    h = tf.keras.layers.Dense(128)(h)\n",
        "    h = tf.keras.layers.BatchNormalization()(h)\n",
        "    h = tf.keras.layers.Activation('relu')(h)\n",
        "\n",
        "    h = tf.keras.layers.Dense(128)(h)\n",
        "    h = tf.keras.layers.BatchNormalization()(h)\n",
        "    h = tf.keras.layers.Activation('relu')(h)\n",
        "\n",
        "    h = tf.keras.layers.Dense(128)(h)\n",
        "    h = tf.keras.layers.BatchNormalization()(h)\n",
        "    h = tf.keras.layers.Activation('relu')(h)\n",
        "\n",
        "    h = tf.keras.layers.Dense(inputDim)(h)\n",
        "\n",
        "    return tf.keras.models.Model(inputs=inputLayer, outputs=h)\n",
        "\n",
        "\n",
        "# https://github.com/mlcommons/tiny_results_v0.5/blob/main/closed/reference/code/training/anomaly_detection/00_train.py#L197\n",
        "#model = keras_model.get_model(param[\"feature\"][\"n_mels\"] * param[\"feature\"][\"frames\"])\n",
        "\n",
        "# params: https://github.com/mlcommons/tiny_results_v0.5/blob/main/closed/reference/code/training/anomaly_detection/baseline.yaml\n",
        "\n",
        "INPUT_DIM = 128 * 5\n",
        "ad_model = get_model(INPUT_DIM)\n",
        "#ad_model.summary()"
      ],
      "metadata": {
        "id": "GIBawR-b2k3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_SAMPLES = 32_768\n",
        "rng = np.random.default_rng()\n",
        "samples = rng.random((N_SAMPLES, INPUT_DIM), dtype=np.float32)\n",
        "\n",
        "timings = {}\n",
        "for batch_size  in [8, 16, 32, 64, 128, 256, 512]:\n",
        "    start = datetime.datetime.now()\n",
        "    ds = (\n",
        "        tf.data.Dataset.from_tensor_slices(samples)\n",
        "        .batch(batch_size)\n",
        "        .prefetch(tf.data.AUTOTUNE)\n",
        "    )    \n",
        "    results = ad_model.predict(ds)\n",
        "    end = datetime.datetime.now()\n",
        "    timings[batch_size] = end - start\n",
        "timings"
      ],
      "metadata": {
        "id": "1RJM_c_qI_mp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mobilenet = tf.keras.applications.MobileNet()"
      ],
      "metadata": {
        "id": "hVSVnW6HA56O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N_IMAGES = 512\n",
        "rng = np.random.default_rng()\n",
        "images = rng.integers(0, 255, size=(N_IMAGES, 224,224,3), dtype=np.uint8)\n",
        "\n",
        "timings = {}\n",
        "for batch_size  in [8, 16, 32, 64, 128]:\n",
        "    start = datetime.datetime.now()\n",
        "    ds = (\n",
        "        tf.data.Dataset.from_tensor_slices(tf.keras.applications.mobilenet.preprocess_input(images))\n",
        "        .batch(batch_size)\n",
        "        .prefetch(tf.data.AUTOTUNE)\n",
        "    )    \n",
        "    results = mobilenet.predict(ds)\n",
        "    end = datetime.datetime.now()\n",
        "    timings[batch_size] = end - start"
      ],
      "metadata": {
        "id": "1kh6_o40ERea"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "timings"
      ],
      "metadata": {
        "id": "XF439HbhCoV6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}